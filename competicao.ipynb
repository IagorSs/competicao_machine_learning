{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   COMPETIÇÃO\n",
    "\n",
    "Alunos Felipe Morais\n",
    "       Iagor Sousa\n",
    "       \n",
    "                                               MISSÃO\n",
    "       \n",
    "   **`PEGAR OS QUE MAIS REPETEM E, NUM DATA FRAME GRANDE, USAR ISSO COMO PARÂMETRO PARA IDENTIFICAR O GÊNERO`**\n",
    "\n",
    "\n",
    "   Resposta às perguntas propostas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1.` Como se escolheu o conjuntos de parâmetros?\n",
    "\n",
    "Discutimos e observamos que os principais parâmetros a serem utilizados seriam os nomes dos **`Escritores`** e **`Diretores`**; \n",
    "\n",
    "É muito incomum que escritores sejam adeptos de mais de um gênero de escrita e diretores são estimulados a buscar um gênero específico onde possam se tornar memoráveis por aquele tipo de filme, tornando-se uma referência na área;\n",
    "\n",
    " Além disso, decidimos **analisar os resumos**, em busca de `palavras-chave` que remetessem mais comumente a narrativas de cada um do gêneros. Ao encontrá-las, usaríamos os dados encontrados no treino para tentar encontrá-los nos testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2.` Qual foi a representação adotada?\n",
    "\n",
    "Adotamos a representação `_Bag Of Itens_`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-17dbb380f1a7>, line 4)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-17dbb380f1a7>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    Após estudá-la, juntamente com os exemplos deixado no documento de instruções, pudemos definir a melhor utilidade para a `Bag Of Itens` no nosso modelo;\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### `3.` Como vocẽs chegaram nesta representação? \n",
    "\n",
    "\n",
    "Após estudá-la, juntamente com os exemplos deixado no documento de instruções, pudemos definir a melhor utilidade para a `Bag Of Itens` no nosso modelo;\n",
    "\n",
    "Assim, nos aproveitamos da maneira como ela usufrui do parâmetro `_min_occur_` e da distribuição dos nomes já como atributos de um dataframe para melhor filtrarmos os dados que fossem nos auxiliar no processo decidido. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.` Quais métodos foram adotados?\n",
    "\n",
    "O método resumidamente utilizado foi:\n",
    "\n",
    "### ETAPA 1: _ELENCAR OS DADOS_\n",
    "\n",
    " Parâmetros para se guiar:\n",
    "\n",
    "1 .**Diretor** --> \n",
    "\n",
    "  - Filtrar os diretores de **ação** e **comédia** separando-os em diferentes _df_ para treinar; \n",
    "  \n",
    "  \n",
    "  - Lidar com os vazios ou faltosos;\n",
    "  \n",
    "  \n",
    "  - Depois de armazená-los, testar no _df_ de teste com as infos obtidas pela análise do _df_ de treino;  \n",
    "  \n",
    "  \n",
    "  - Se encontrado, classificá-lo, se não atribuir uma classificação _default_.\n",
    "\n",
    "\n",
    "2 .**Escritor** -->\n",
    "\n",
    "  - Filtrar os escritores de **ação** e **comédia** separando-os em diferentes _df_ para treinar;\n",
    "  \n",
    "  \n",
    "  - Lidar com os vazios ou faltosos;\n",
    "  \n",
    "  \n",
    "  - Depois de armazená-los, testar no _df_ de teste com as infos obtidas pela análise do _df_ de treino\n",
    "  \n",
    "  \n",
    "  - Pontuar as ocorrências de cada gênero e definir classificações. Inconclusivos, atribuir _default_.\n",
    "\n",
    "\n",
    "3 .**Resumo**   -->\n",
    "\n",
    "- Filtrar os resumos de **ação** e **comédia** separando-os em diferentes _df_ para treinar;\n",
    "\n",
    "\n",
    "- Formatar os textos para retirar pontuações, CAPS LOCK, etc... \n",
    "\n",
    "\n",
    "- Calcular _IDF_ dessas palavras;\n",
    "\n",
    "\n",
    "- Retirar as palavras iguais encontradas de ambos os gêneros;\n",
    "\n",
    "\n",
    "- Filtrar para retirar as palavras ainda muito discriminativas;\n",
    "\n",
    "\n",
    "- Melhor dividir as agora refinadas palavras entre seu gênero específico;\n",
    "\n",
    "\n",
    "-  Pontuar as ocorrências de cada gênero e definir classificações. Inconclusivos, atribuir _default_\n",
    "\n",
    "\n",
    "### ETAPA 2: __COMBINAR OS DADOS__\n",
    "\n",
    " Combinar as pontuações atribuídas e resultados encontrados em ambos ou processos para enfim obter uma classificação apurada do gênero específico de cada um dos documentos (filmes) analisados\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ETAPA 3:  __APONTAR O GÊNERO__\n",
    "\n",
    "Verificadas as informações e dados coletados, apontar o gênero de cada filme a ser predito e concluir pelo Resultado.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Criamos diversas funções para servir de apoio a nossa representação. Todos as usadas foram:\n",
    "\n",
    "\n",
    " 1. De _`resultado_competicao.py`_\n",
    " - _convert_list_to_int()_.\n",
    "\n",
    " 2. De `_preprocessamento_atributos_competicao.py_` \n",
    " - _standart_text()_,\n",
    " - _words_IDF()_,\n",
    " - _calcula_IDF()_,\n",
    " - _zerolistmaker()_,\n",
    " - _gerar_atributos_diretor()_.\n",
    " \n",
    " \n",
    " 3. De `_metodo_competicao.py_`\n",
    " - _genero_df()_,\n",
    " - _diretores()_,\n",
    " - _escritores()_,\n",
    " - _clean_list()_,\n",
    " - _eval_diretores()_,\n",
    " - _eval_escritores()_,\n",
    " - _eval_resumos()_,\n",
    " - _combine_predictions()_,\n",
    " - _eval()_.\n",
    "\n",
    " 4. De `_gerar_resultado_teste.py_`\n",
    " - _gerar_saida_teste()_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `5.` Explicar a implementação da função _gerar_saida_teste()_ do arquivo `gerar_resultado_teste.py`\n",
    "\n",
    "- Ler o dataframe de treino;\n",
    "\n",
    "\n",
    "- Os valores de predição serão gerados e atribuídos conforme seus resultados do `_eval_`, detalhados no método;\n",
    "\n",
    "\n",
    "- Combina-se a predições segundo o sistema de pontuação-e-atribuição definido pelos `_eval_`\n",
    "\n",
    "\n",
    "- Cria, gera e imprime os resultados obtidos no processo do método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<function competicao_am.gerar_resultado_teste.gerar_saida_teste(df_data_to_predict, col_classe, num_grupo)>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from competicao_am.gerar_resultado_teste import gerar_saida_teste\n",
    "\n",
    "gerar_saida_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar palavras-chave encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 32-bit",
   "name": "python_defaultSpec_1597872794029"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}